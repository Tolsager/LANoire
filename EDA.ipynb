{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "from LANoire.dataset import get_data_split_ids, LANoireIndexDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>subjects</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'16_the_naked_city': {'id': 16, 'chapter id':...</td>\n",
       "      <td>{'virginia_reynoldson': {'id': 1, 'case id': 1...</td>\n",
       "      <td>{'q1': {'id': 1, 'subject id': 1, 'subject nam...</td>\n",
       "      <td>{'a1': {'id': 1, 'subject id': 1, 'question id...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               cases  \\\n",
       "0  {'16_the_naked_city': {'id': 16, 'chapter id':...   \n",
       "\n",
       "                                            subjects  \\\n",
       "0  {'virginia_reynoldson': {'id': 1, 'case id': 1...   \n",
       "\n",
       "                                           questions  \\\n",
       "0  {'q1': {'id': 1, 'subject id': 1, 'subject nam...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'a1': {'id': 1, 'subject id': 1, 'question id...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/raw/data.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = df[\"cases\"][0]\n",
    "subjects = df[\"subjects\"][0]\n",
    "questions = df[\"questions\"][0]\n",
    "answers = df[\"answers\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16_the_naked_city',\n",
       " '8_the_golden_butterfly',\n",
       " '13_the_black_ceasar',\n",
       " '17_manifest_destiny',\n",
       " '15_the_set_up',\n",
       " '14_reefer_madness',\n",
       " '6_the_fallen_idol',\n",
       " '18_the_gas_man',\n",
       " '3_the_consuls_car',\n",
       " '5_a_slip_of_tongue',\n",
       " '10_the_white_shoe_slaying',\n",
       " '1_buyers_beware',\n",
       " '7_the_lipstick_murder',\n",
       " '20_house_of_sticks',\n",
       " '2_the_drivers_seat',\n",
       " '4_a_marriage_made_in_heaven',\n",
       " '9_the_silk_stocking_murder',\n",
       " '21_a_polite_invitation',\n",
       " '19_a_walk_in_elysian_fields',\n",
       " '11_the_studio_secretary_murder',\n",
       " '22_nicholson_electroplating']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cases.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 16,\n",
       " 'chapter id': 1,\n",
       " 'folder': '/work3/s213233/thesis/dataset/16_the_naked_city',\n",
       " 'name': '16_the_naked_city',\n",
       " 'subjects': ['virginia_reynoldson',\n",
       "  'dassine_store_owner',\n",
       "  'heather_swanson',\n",
       "  'dr_stoneman',\n",
       "  'henry_arnett',\n",
       "  'beverly_everstrom'],\n",
       " 'clues': ''}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases[\"16_the_naked_city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginia_reynoldson',\n",
       " 'dassine_store_owner',\n",
       " 'heather_swanson',\n",
       " 'dr_stoneman',\n",
       " 'henry_arnett']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(subjects.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'case id': 16,\n",
       " 'name': 'virginia_reynoldson',\n",
       " 'sex': 'M',\n",
       " 'questions': ['q1', 'q2', 'q3']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects[\"virginia_reynoldson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q1', 'q2', 'q3', 'q5', 'q7']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(questions.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'subject id': 1,\n",
       " 'subject name': 'virginia_reynoldson',\n",
       " 'name': 'q2',\n",
       " 'duration': 4.048979591836734,\n",
       " 'text': 'Did Miss Randall have many friends, is it? ',\n",
       " 'text file': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/transcript/virginia_reynoldson_question_2.txt',\n",
       " 'audio file': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/virginia_reynoldson_question_2.mp3',\n",
       " 'spectrogram': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/transcript/virginia_reynoldson_question_2_mel.npy',\n",
       " 'answers': ['a1', 'a2', 'a3', 'a4']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[\"q1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1', 'a2', 'a3', 'a4', 'a5']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(answers.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'subject id': 1,\n",
       " 'question id': 1,\n",
       " 'name': 'virginia_reynoldson_lie_2.mp3',\n",
       " 'duration': 4.048979591836734,\n",
       " 'class': 'lie',\n",
       " 'text': \"I'm not sure. I only come around twice a week. \",\n",
       " 'text file': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/transcript/virginia_reynoldson_lie_2.txt',\n",
       " 'audio file': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/virginia_reynoldson_lie_2.mp3',\n",
       " 'spectrogram': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/transcript/virginia_reynoldson_lie_2_mel.npy',\n",
       " 'image prefix': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/original/virginia_reynoldson_lie_2',\n",
       " 'bounding boxes': '/work3/s213233/thesis/dataset/16_the_naked_city/virginia_reynoldson/q2/retina/virginia_reynoldson_lie_2'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[\"a1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_audio, sr = librosa.load(\"data/raw/1_buyers_beware/clovis_galletta/q1/clovis_galletta_lie_0.mp3\", sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "n_questions = len(glob.glob(\"data/raw/*/*/q*\"))\n",
    "n_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, val_ids, test_ids = get_data_split_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LANoireIndexDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [ds[i][1] for i in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.5923077)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels = [ds[i][1] for i in val_ids if i != 650]\n",
    "np.mean(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mispredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LANoire.utils import load_pickle\n",
    "err = load_pickle(\"data/processed/whisper_errors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(533), tensor(0.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[533]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 376,\n",
       " 'subject id': 45,\n",
       " 'question id': 208,\n",
       " 'name': 'lars_taraldsen_lie_0.mp3',\n",
       " 'duration': 6.034285714285715,\n",
       " 'class': 'lie',\n",
       " 'text': \"Everyone loved Teresa. She was so full of life. It can't be anyone who knew her. \",\n",
       " 'text file': '/work3/s213233/thesis/dataset/10_the_white_shoe_slaying/lars_taraldsen/q1/transcript/lars_taraldsen_lie_0.txt',\n",
       " 'audio file': '/work3/s213233/thesis/dataset/10_the_white_shoe_slaying/lars_taraldsen/q1/lars_taraldsen_lie_0.mp3',\n",
       " 'spectrogram': '/work3/s213233/thesis/dataset/10_the_white_shoe_slaying/lars_taraldsen/q1/transcript/lars_taraldsen_lie_0_mel.npy',\n",
       " 'image prefix': '/work3/s213233/thesis/dataset/10_the_white_shoe_slaying/lars_taraldsen/q1/original/lars_taraldsen_lie_0',\n",
       " 'bounding boxes': '/work3/s213233/thesis/dataset/10_the_white_shoe_slaying/lars_taraldsen/q1/retina/lars_taraldsen_lie_0'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.answers[\"a376\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Multimodal language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\programming\\LANoire\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\victo\\programming\\LANoire\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\victo\\.cache\\huggingface\\hub\\models--Qwen--Qwen-Audio-Chat. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-Audio-Chat:\n",
      "- audio.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-Audio-Chat:\n",
      "- audio.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-Audio-Chat:\n",
      "- configuration_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Encountered exception while importing einops: No module named 'einops'\n",
      "Encountered exception while importing transformers_stream_generator: No module named 'transformers_stream_generator'\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "This modeling file requires the following packages that were not found in your environment: einops, transformers_stream_generator. Run `pip install einops transformers_stream_generator`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationConfig\n\u001b[32m      4\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen-Audio-Chat\u001b[39m\u001b[33m\"\u001b[39m, trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQwen/Qwen-Audio-Chat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.eval()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Specify hyperparameters for generation (No need to do this if you are using transformers>4.32.0)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-Audio-Chat\", trust_remote_code=True)\u001b[39;00m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 1st dialogue turn\u001b[39;00m\n\u001b[32m     12\u001b[39m query = tokenizer.from_list_format([\n\u001b[32m     13\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33maw\u001b[39m\u001b[38;5;130;01m\\1\u001b[39;00m\u001b[33m_buyers_beware\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mclovis_galletta\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mq1\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mclovis_galletta_lie_0.mp3\u001b[39m\u001b[33m'\u001b[39m}, \u001b[38;5;66;03m# Either a local path or an url\u001b[39;00m\n\u001b[32m     14\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mIs the person lying?\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     15\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\victo\\programming\\LANoire\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:553\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[32m    552\u001b[39m     class_ref = config.auto_map[\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     model_class = \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    556\u001b[39m     _ = hub_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mcls\u001b[39m.register(config.\u001b[34m__class__\u001b[39m, model_class, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\victo\\programming\\LANoire\\.venv\\Lib\\site-packages\\transformers\\dynamic_module_utils.py:541\u001b[39m, in \u001b[36mget_class_from_dynamic_module\u001b[39m\u001b[34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[39m\n\u001b[32m    539\u001b[39m     code_revision = revision\n\u001b[32m    540\u001b[39m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m final_module = \u001b[43mget_cached_module_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_file\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.py\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_class_in_module(class_name, final_module, force_reload=force_download)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\victo\\programming\\LANoire\\.venv\\Lib\\site-packages\\transformers\\dynamic_module_utils.py:366\u001b[39m, in \u001b[36mget_cached_module_file\u001b[39m\u001b[34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# Check we have all the requirements in our environment\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m modules_needed = \u001b[43mcheck_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_module_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# Now we move the module inside our cached dynamic modules.\u001b[39;00m\n\u001b[32m    369\u001b[39m full_submodule = TRANSFORMERS_DYNAMIC_MODULE_NAME + os.path.sep + submodule\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\victo\\programming\\LANoire\\.venv\\Lib\\site-packages\\transformers\\dynamic_module_utils.py:198\u001b[39m, in \u001b[36mcheck_imports\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m    195\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_packages) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    199\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis modeling file requires the following packages that were not found in your environment: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    201\u001b[39m     )\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_relative_imports(filename)\n",
      "\u001b[31mImportError\u001b[39m: This modeling file requires the following packages that were not found in your environment: einops, transformers_stream_generator. Run `pip install einops transformers_stream_generator`"
     ]
    }
   ],
   "source": [
    "# QWEN\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-Audio-Chat\", trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio-Chat\", trust_remote_code=True).eval()\n",
    "\n",
    "# Specify hyperparameters for generation (No need to do this if you are using transformers>4.32.0)\n",
    "# model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-Audio-Chat\", trust_remote_code=True)\n",
    "\n",
    "# 1st dialogue turn\n",
    "query = tokenizer.from_list_format([\n",
    "    {'audio': 'data\\raw\\1_buyers_beware\\clovis_galletta\\q1\\clovis_galletta_lie_0.mp3'}, # Either a local path or an url\n",
    "    {'text': 'Is the person lying?'},\n",
    "])\n",
    "response, history = model.chat(tokenizer, query=query, history=None)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
